{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주피터 노트북 환경설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"retina\")\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { font-weight: bold !important; font-family:'Malgun Gothic' !important;}</style>\"))\n",
    "display(HTML(\"<style>.container { font-weight: bold !important;}</style>\"))\n",
    "display(HTML(\"<style>.container { width: 98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 관련 라이브러리 임포트 \n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "#  한글글꼴로 변경\n",
    "# plt.rcParams['font.family'] = '한글글꼴명'\n",
    "plt.rcParams['font.size'] = 11.0\n",
    "# plt.rcParams['font.family'] = 'batang'\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "# 그래프에서 마이너스 폰트 깨지는 문제에 대한 대처\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그래프 기본 크기 설정 \n",
    "# plt.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류(Classfication)\n",
    "\n",
    "- 학습데이터로 주어진 데이터의 피처와 레이블값(결정값, 클래스값)을 머신러닝 알고리즘으로 학습해 모델을 생성하고 이렇게 생성된 모델에 새로운 데이터값이 주어졌을 때 미지의 값을 예측한다.\n",
    "\n",
    "\n",
    "    - K Nearest Neighbor : 근접 거리를 기준으로 하는 최소 근접 알고리즘 \n",
    "    - Ensemble : 서로 다른 또는 같은 머신러닝 알고리즘을 결합하는 알고리즘 \n",
    "    - Logistic Regression : 독립변수와 종속변수의 선형 관계성에 기반\n",
    "    - SVM(support Vector Machine) : 개별 클래스간의 최대 분류 마진이용 \n",
    "    - Decision Tree :  트리기반 분류 규칙의 알고리즘 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정트리 \n",
    "\n",
    "- 스무고개 형태로 질문을 하나씩 던져서 정답을 맞추어 나간다. \n",
    "- sklearn의 DecisionTreeClassifier 클래스에서 제공\n",
    "- 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리 기반의 분류 규칙을 만든다. (If-Else 기반 규칙)\n",
    "- 쉽고 직관적이다. 데이타의 스케일링이나 정규화 등의 사전 가공의 영향이 매우 적다. \n",
    "- 단점은 과적합으로 알고리즘 성능이 떨어진다. 이를 극복하기 위해 트리의  크기를 사전에 제한하는 튜닝이 필요하다. \n",
    "- GBM, XGBoodt, LightGBM과 같은 앙상블 학습기의 기반이 된다.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/f/fe/CART_tree_titanic_survivors_KOR.png' width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정트리에 사용되는 Terms\n",
    "\n",
    "- 결정트리 알고리즘 원리 \n",
    "    - 결정트리는 부모노드와 자식노드의 불순도 차이가 가능한 크도록 트리를 성장시킨다. \n",
    "    - 불순도 기준을 사용해 정보 이득이 최대가 되도록 노드를 분할한다. \n",
    "\n",
    "\n",
    "- 불순도(impurity)\n",
    "    - 결정트리가 최적의 질문을 찾기 위한 기준. \n",
    "    - 노드에서 데이터를 분할하는 기준을 정한다. \n",
    "    - 불순도 기준으로 criterion 파라미터를 사용하며 gini, entropy 가 있다. \n",
    "    - 기본값은 gini \n",
    "    - criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
    "\n",
    "\n",
    "- 지니 불순도 \n",
    "    - 경제학 용어 코라도 지니의 이름에서 딴 지니계수에서 유래 \n",
    "    - 다양성을 계산하는 방법\n",
    "    - 데이타의 불평등이 높을수록 1에 가깝다.\n",
    "    - 1 - (음성클래스비율의제곱 + 양성클래스비율의제곱)\n",
    "    - 지니불순도가 0이면 순수 노드라고 한다. \n",
    "    - 0이 가장 평등. 1로 갈수록 불평등.\n",
    "\n",
    "    \n",
    "    \n",
    "- 엔트로피 불순도 \n",
    "     - 지니 불순도와 같이 노드의 클래스 비율을 사용하지만 제곱이 아닌 밑이 2인 로그를 사용하여 곱한다. \n",
    "\n",
    "\n",
    "- 정보 이득(Information Gain) \n",
    "    - 부모와 자식 노드사이의 불순도 차이 \n",
    "    - 엔트로피 개념 기반. 엔트로피는 주어진 데이터 집합의 혼합도\n",
    "    - 정보이득 지수는 1-엔트로피지수 \n",
    "  \n",
    "\n",
    "#### 결정트리 구성 \n",
    "- 루트노드 \n",
    "- 규칙노드 : 규칙조건 \n",
    "- 리프 노드 : 결정된 분류값 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정트리 주요 하이퍼파라미터 \n",
    "\n",
    "max_depth \n",
    "- 트리의 최대 깊이. \n",
    "\n",
    "max_features\n",
    "- 최적의 분할을 위해 고려할 최대 피처 갯수 \n",
    "\n",
    "min_samples_split \n",
    "- 노드를 분할하기 위한 최소한의 샘플 데이터수. 디폴트는 2이고 작게 설정할 수록 분할되는 노드가 많아져 과적합 가능성이 증가한다. \n",
    "\n",
    "min_samples_leaf\n",
    "- 말단노드(Leaf)가 되기위한 최소한의 샘플 데이터 수 \n",
    "\n",
    "max_leaf_nodes \n",
    "- 말단 노드의 최대 개수 \n",
    "\n",
    "\n",
    "## Fature 선택 중요도 \n",
    "- DecisionClassifier 객체의 feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정 트리 모델의 시각화\n",
    "\n",
    "- 붓꽃 데이타셋 이용 \n",
    "- plot_tree => 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "print(iris_data.data.shape)\n",
    "X_train , X_test , y_train , y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                       test_size=0.3,  random_state=11, stratify=iris_data.target)\n",
    "\n",
    "model_dt = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "model_dt.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_tree\n",
    "\n",
    "- graphviz 보다 편리 \n",
    "- 결정트리 모델를 트리 형태로 표시 \n",
    "- sklearn.tree 에서 지원 \n",
    "\n",
    "plot_tree(모델명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plot_tree(model_dt)\n",
    "\n",
    "plt.savefig('output/iris_tree1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls output\\*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename = 'output//iris_tree1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세부 속성 제어 \n",
    "- plot_tree(모델명, max_depth=n, filled=True, feature_names=컬럼명리스트)\n",
    "- max_depth 트리의 깊이\n",
    "- filled=True 클래스에 맞게 색상화 \n",
    "- feature_names = 리스트 매개변수에 특성의 이름을 전달\n",
    "- class_names = 리스트. 타겟 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨명\n",
    "iris_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명\n",
    "iris_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plot_tree(model_dt, max_depth=1, filled=True, feature_names=iris_data.feature_names)\n",
    "plt.savefig('output/iris_tree2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_iris = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
    "df_iris['label'] = iris_data.target\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(data=X_train, columns=iris_data.feature_names) \n",
    "X_train_df['label'] = y_train\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x='petal length (cm)', y='petal width (cm)', hue='label', data=X_train_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x='sepal length (cm)', y='sepal width (cm)', hue='label', data=X_train_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가지치기\n",
    "\n",
    "- 결정트리의 하이퍼파라미터를 지정하여 트리를 제한한다. \n",
    "- 시간 단축 및 과적합 방지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,14))\n",
    "plot_tree(model_dt, max_depth=3, filled=True, feature_names=iris_data.feature_names)\n",
    "plt.savefig('output/iris_tree3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중요 속성\n",
    "\n",
    "- feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(iris_data.feature_names , model_dt.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=model_dt.feature_importances_ , y=iris_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test , model_dt.predict(X_test)))\n",
    "print(accuracy_score(y_train , model_dt.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model_dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그리드서치 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth' : [ 4, 6, 8 ,10, 12, 16 ,20, 24]\n",
    "}\n",
    "\n",
    "\n",
    "grid_cv = GridSearchCV(model_dt, param_grid=params, scoring='accuracy', cv=5, verbose=1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('GridSearchCV 최고 평균 정확도 수치:{0:.4f}'.format(grid_cv.best_score_))\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt2 = DecisionTreeClassifier(max_depth=6)\n",
    "model_dt2.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, model_dt2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, model_dt2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,14))\n",
    "plot_tree(model_dt2, max_depth=8, filled=True, feature_names=iris_data.feature_names)\n",
    "plt.savefig('output/iris_tree5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(grid_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [ 4, 6, 8 ,10, 12, 16 ,20, 24]\n",
    "\n",
    "for depth in max_depths:\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=depth, random_state=156)\n",
    "    dt_clf.fit(X_train , y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    print('max_depth = {0} 정확도: {1:.4f}'.format(depth , accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth' : [ 8 , 12, 16 ,20], \n",
    "    'min_samples_split' : [16,24],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('GridSearchCV 최고 평균 정확도 수치: {0:.4f}'.format(grid_cv.best_score_))\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df_clf = grid_cv.best_estimator_\n",
    "\n",
    "pred1 = best_df_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred1)\n",
    "print('결정 트리 예측 정확도:{0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
