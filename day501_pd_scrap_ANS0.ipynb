{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40796956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { font-weight: bold !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 쥬피터노트북 셀 스타일 조절 \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { font-weight: bold !important; }</style>\"))\n",
    "display(HTML(\"<style>.container { width: 100% !important; }</style>\"))\n",
    "\n",
    "# 경고 메세지 숨기기 \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c1414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628945f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79070226",
   "metadata": {},
   "source": [
    "# 알렉사 사이트\n",
    "\n",
    "https://www.alexa.com/topsites\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c22158da",
   "metadata": {},
   "source": [
    "1) requests 모듈 이용 페이지 요청 => html 페이지를 텍스트로 저장 \n",
    "2) BeautifulSoup 이용 html 페이지(str) => soup 객체\n",
    "3) 필요한 요소만 리스트로 저장 \n",
    "4) 리스트 => 데이타프레임 \n",
    "5) 데이타프레임 => csv 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5753aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# 1) requests 모듈 페이지 요청 => html 페이지를 텍스트로 저장 \n",
    "url = 'https://www.alexa.com/topsites'\n",
    "res = requests.get(url)\n",
    "# 200 이면 성공 \n",
    "print(res) \n",
    "# html 페이지를 텍스트로 저장 \n",
    "html_str = res.text\n",
    "print(type(html_str))\n",
    "# print(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c3867d",
   "metadata": {},
   "outputs": [],
   "source": [
    " BeautifulSoup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d8342a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) BeautifulSoup() 이용... html 페이지(str) => soup 객체\n",
    "#  BeautifulSoup(html페이지소스, 파서(html.parser/lxml/xml))\n",
    "soup = BeautifulSoup(html_str, 'html.parser')\n",
    "print(type(soup))\n",
    "print()\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7faf7e",
   "metadata": {},
   "source": [
    "### soup 필터링 메서드 \n",
    "\n",
    "- find(태그/클래스/아이디) => 첫번째 요소 \n",
    "- find_all(class_='클래스명') => 전체 요소 클래스 리스트\n",
    "- find_all('태그명', {'class':'클래스명'}) => 전체 태그 요소 리스트\n",
    "\n",
    "- select(css선택자) => 리스트 \n",
    "- select_one(css선택자) => 첫번째 요소 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72ad8825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"hdr title\">\n",
      "<span class=\"page-title-text\">The top 500 sites on the web</span>\n",
      "<span class=\"WhatsThis top\">\n",
      "<i aria-hidden=\"true\" class=\"fa fa-question-circle\"></i>\n",
      "<span class=\"container\">\n",
      "                The sites in the top sites lists are ordered by their 1 month             Alexa traffic rank.<br/><br/>The 1 month rank is calculated using a             combination of average daily visitors and pageviews over the past             month. The site with the highest combination of visitors and             pageviews is ranked #1\n",
      "              </span>\n",
      "</span>\n",
      "</h1>\n",
      "==================================================\n",
      "<span class=\"page-title-text\">The top 500 sites on the web</span>\n",
      "==================================================\n",
      "<span class=\"container\">\n",
      "                The sites in the top sites lists are ordered by their 1 month             Alexa traffic rank.<br/><br/>The 1 month rank is calculated using a             combination of average daily visitors and pageviews over the past             month. The site with the highest combination of visitors and             pageviews is ranked #1\n",
      "              </span>\n"
     ]
    }
   ],
   "source": [
    "# h1 태그안의 소스 핸들링 - find 이용 \n",
    "print(soup.find('h1')) # h1 태그 소스를 찾아줘 \n",
    "print('='*50)\n",
    "print(soup.find(class_='page-title-text')) # class 값이 page-title-text 인 소스를 찾아줘 \n",
    "print('='*50)\n",
    "print(soup.find(class_='container')) # class 값이 container 인 소스를 찾아줘 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ea8fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 class=\"hdr title\">\n",
      "<span class=\"page-title-text\">The top 500 sites on the web</span>\n",
      "<span class=\"WhatsThis top\">\n",
      "<i aria-hidden=\"true\" class=\"fa fa-question-circle\"></i>\n",
      "<span class=\"container\">\n",
      "                The sites in the top sites lists are ordered by their 1 month             Alexa traffic rank.<br/><br/>The 1 month rank is calculated using a             combination of average daily visitors and pageviews over the past             month. The site with the highest combination of visitors and             pageviews is ranked #1\n",
      "              </span>\n",
      "</span>\n",
      "</h1>]\n",
      "==================================================\n",
      "[<span class=\"page-title-text\">The top 500 sites on the web</span>]\n",
      "==================================================\n",
      "container_list 전체갯수는? 5\n",
      "<class 'bs4.element.ResultSet'>\n",
      "\n",
      "                The sites in the top sites lists are ordered by their 1 month             Alexa traffic rank.The 1 month rank is calculated using a             combination of average daily visitors and pageviews over the past             month. The site with the highest combination of visitors and             pageviews is ranked #1\n",
      "              \n",
      "\n",
      "Daily Time on SiteEstimated daily time on site (mm:ss) per visitor to the site. Updated daily based on the trailing 3 months.\n",
      "                        \n",
      "\n",
      "Daily Pageviews per VisitorEstimated daily unique pageviews per visitor on the site. Updated daily based on the trailing 3 months.\n",
      "                        \n",
      "\n",
      "% of Traffic From SearchThe percentage of all referrals that came from Search engines over the trailing month. Updated daily.\n",
      "                        \n",
      "\n",
      "Total Sites Linking InThe total number of sites that Alexa found that link to this site. For more information please see this explanation of how Alexa determines the number of sites linking in.\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# h1 태그안의 소스 핸들링 - find_all 이용 => 리스트\n",
    "print(soup.find_all('h1')) # h1 태그 소스를 찾아줘 \n",
    "print('='*50)\n",
    "print(soup.find_all(class_='page-title-text')) # class 값이 page-title-text 인 소스를 찾아줘 \n",
    "print('='*50)\n",
    "# class 값이 container 인 소스를 전체를 찾아서 리스트에 저장해줘 \n",
    "# print(soup.find_all(class_='container')) \n",
    "container_list = soup.find_all(class_='container')\n",
    "print('container_list 전체갯수는?', len(container_list))\n",
    "print(type(container_list))\n",
    "# 텍스트만 출력해줘 \n",
    "# 요소.text \n",
    "for item in container_list:\n",
    "    print(item.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc6baaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"hdr title\">\n",
      "<span class=\"page-title-text\">The top 500 sites on the web</span>\n",
      "<span class=\"WhatsThis top\">\n",
      "<i aria-hidden=\"true\" class=\"fa fa-question-circle\"></i>\n",
      "<span class=\"container\">\n",
      "                The sites in the top sites lists are ordered by their 1 month             Alexa traffic rank.<br/><br/>The 1 month rank is calculated using a             combination of average daily visitors and pageviews over the past             month. The site with the highest combination of visitors and             pageviews is ranked #1\n",
      "              </span>\n",
      "</span>\n",
      "</h1>\n",
      "==================================================\n",
      "<span class=\"page-title-text\">The top 500 sites on the web</span>\n",
      "==================================================\n",
      "<span class=\"container\">\n",
      "                The sites in the top sites lists are ordered by their 1 month             Alexa traffic rank.<br/><br/>The 1 month rank is calculated using a             combination of average daily visitors and pageviews over the past             month. The site with the highest combination of visitors and             pageviews is ranked #1\n",
      "              </span>\n"
     ]
    }
   ],
   "source": [
    "# h1 태그안의 소스 핸들링 - select_one 이용 \n",
    "# select_one('css선택자')\n",
    "# css선택자는 클래스인 경우 .클래스명, 아이디는 #아이디명\n",
    "print(soup.select_one('h1')) # h1 태그 소스를 찾아줘 \n",
    "print('='*50)\n",
    "print(soup.select_one('.page-title-text')) # class 값이 page-title-text 인 소스를 찾아줘 \n",
    "print('='*50)\n",
    "print(soup.select_one('.container')) # class 값이 container 인 소스를 찾아줘 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eed4e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 class=\"hdr title\">\n",
      "<span class=\"page-title-text\">The top 500 sites on the web</span>\n",
      "<span class=\"WhatsThis top\">\n",
      "<i aria-hidden=\"true\" class=\"fa fa-question-circle\"></i>\n",
      "<span class=\"container\">\n",
      "                The sites in the top sites lists are ordered by their 1 month             Alexa traffic rank.<br/><br/>The 1 month rank is calculated using a             combination of average daily visitors and pageviews over the past             month. The site with the highest combination of visitors and             pageviews is ranked #1\n",
      "              </span>\n",
      "</span>\n",
      "</h1>]\n",
      "==================================================\n",
      "[<span class=\"page-title-text\">The top 500 sites on the web</span>]\n",
      "==================================================\n",
      "container_list 전체갯수는? 5\n",
      "<class 'bs4.element.ResultSet'>\n",
      "\n",
      "                The sites in the top sites lists are ordered by their 1 month             Alexa traffic rank.The 1 month rank is calculated using a             combination of average daily visitors and pageviews over the past             month. The site with the highest combination of visitors and             pageviews is ranked #1\n",
      "              \n",
      "\n",
      "Daily Time on SiteEstimated daily time on site (mm:ss) per visitor to the site. Updated daily based on the trailing 3 months.\n",
      "                        \n",
      "\n",
      "Daily Pageviews per VisitorEstimated daily unique pageviews per visitor on the site. Updated daily based on the trailing 3 months.\n",
      "                        \n",
      "\n",
      "% of Traffic From SearchThe percentage of all referrals that came from Search engines over the trailing month. Updated daily.\n",
      "                        \n",
      "\n",
      "Total Sites Linking InThe total number of sites that Alexa found that link to this site. For more information please see this explanation of how Alexa determines the number of sites linking in.\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "# h1 태그안의 소스 핸들링 - select 이용 => 리스트\n",
    "print(soup.select('h1')) # h1 태그 소스를 찾아줘 \n",
    "print('='*50)\n",
    "print(soup.select('.page-title-text')) # class 값이 page-title-text 인 소스를 찾아줘 \n",
    "print('='*50)\n",
    "# class 값이 container 인 소스를 전체를 찾아서 리스트에 저장해줘 \n",
    "container_list = soup.select('.container')\n",
    "print('container_list 전체갯수는?', len(container_list))\n",
    "print(type(container_list))\n",
    "# 텍스트만 출력해줘 \n",
    "# 요소.text \n",
    "for item in container_list:\n",
    "    print(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b2bc820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "==================================================\n",
      "==================================================\n",
      "<div class=\"tr site-listing\">\n",
      "<div class=\"td\">1</div>\n",
      "<div class=\"td DescriptionCell\">\n",
      "<p class=\"\">\n",
      "<a href=\"/siteinfo/google.com\">Google.com</a>\n",
      "</p>\n",
      "</div>\n",
      "<div class=\"td right\"><p>17:23</p></div>\n",
      "<div class=\"td right\"><p>18.41</p></div>\n",
      "<div class=\"td right\"><p>0.20%</p></div>\n",
      "<div class=\"td right\"><p>6,480,338</p></div>\n",
      "</div>\n",
      "==================================================\n",
      "<div class=\"tr site-listing\">\n",
      "<div class=\"td\">50</div>\n",
      "<div class=\"td DescriptionCell\">\n",
      "<p class=\"\">\n",
      "<a href=\"/siteinfo/whatsapp.com\">Whatsapp.com</a>\n",
      "</p>\n",
      "</div>\n",
      "<div class=\"td right\"><p>3:07</p></div>\n",
      "<div class=\"td right\"><p>1.19</p></div>\n",
      "<div class=\"td right\"><p>15.30%</p></div>\n",
      "<div class=\"td right\"><p>659,900</p></div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# 3) 필요한 요소만 리스트로 저장 \n",
    "# 필터링 요소 찾기 - 태그 위주 \n",
    "# 클래스값이 'tr site-listing' 인 태그를 모두 찾아서 리스트에 저장해줘 \n",
    "div_list = soup.find_all(class_='tr site-listing')\n",
    "# div_list = soup.select('.tr.site-listing')\n",
    "print(len(div_list)) # 전체길이 \n",
    "print('='*50)\n",
    "# print(div_list) # 전체 \n",
    "print('='*50)\n",
    "print(div_list[0]) # 첫번째 소스 확인 \n",
    "print('='*50)\n",
    "print(div_list[-1]) # 마지막 소스 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "febffcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Google.com /siteinfo/google.com 18.41\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 요소에 필요한 텍스트만 추출 \n",
    "\n",
    "# 첫번째 div 태그안에 텍스트를 찾아서 저장해줘 \n",
    "rank = div_list[0].find('div').text\n",
    "# 첫번째 a 태그안에 텍스트를 찾아서 저장해줘 \n",
    "site_name = div_list[0].find('a').text\n",
    "# 첫번째 a 태그안에 href 속성값을 찾아서 저장해줘 \n",
    "# [속성], get(속성)\n",
    "# site_url = div_list[0].find('a')['href']\n",
    "site_url = div_list[0].find('a').get('href')\n",
    "# 두번째 'td right' 클래스의 텍스트를 찾아서 저장해줘 \n",
    "page_view = div_list[0].find_all(class_='td right')[1].text\n",
    "print(rank, site_name, site_url, page_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11e8f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 요소를 찾아서 2차원 리스트에 저장 \n",
    "alexa_list = []\n",
    "for row in div_list:\n",
    "    rank = row.find('div').text\n",
    "    site_name = row.find('a').text\n",
    "    site_url = row.find('a').get('href')\n",
    "    page_view = row.find_all(class_='td right')[1].text\n",
    "    # 1차원 리스트로 생성한 후 다시 리스트에 삽입      \n",
    "    alexa_list.append([rank, site_name, site_url, page_view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d690dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 'Google.com', '/siteinfo/google.com', '18.41'], ['2', 'Youtube.com', '/siteinfo/youtube.com', '10.56'], ['3', 'Tmall.com', '/siteinfo/tmall.com', '3.85'], ['4', 'Facebook.com', '/siteinfo/facebook.com', '8.57'], ['5', 'Qq.com', '/siteinfo/qq.com', '3.90'], ['6', 'Baidu.com', '/siteinfo/baidu.com', '4.97'], ['7', 'Sohu.com', '/siteinfo/sohu.com', '4.57'], ['8', 'Taobao.com', '/siteinfo/taobao.com', '3.50'], ['9', '360.cn', '/siteinfo/360.cn', '4.17'], ['10', 'Jd.com', '/siteinfo/jd.com', '4.37'], ['11', 'Amazon.com', '/siteinfo/amazon.com', '10.02'], ['12', 'Yahoo.com', '/siteinfo/yahoo.com', '4.84'], ['13', 'Wikipedia.org', '/siteinfo/wikipedia.org', '3.06'], ['14', 'Weibo.com', '/siteinfo/weibo.com', '3.36'], ['15', 'Sina.com.cn', '/siteinfo/sina.com.cn', '3.37'], ['16', 'Xinhuanet.com', '/siteinfo/xinhuanet.com', '5.71'], ['17', 'Zoom.us', '/siteinfo/zoom.us', '3.57'], ['18', 'Live.com', '/siteinfo/live.com', '5.61'], ['19', 'Netflix.com', '/siteinfo/netflix.com', '3.60'], ['20', 'Reddit.com', '/siteinfo/reddit.com', '4.60'], ['21', 'Microsoft.com', '/siteinfo/microsoft.com', '3.38'], ['22', 'Instagram.com', '/siteinfo/instagram.com', '11.20'], ['23', 'Office.com', '/siteinfo/office.com', '11.29'], ['24', 'Google.com.hk', '/siteinfo/google.com.hk', '5.87'], ['25', 'Panda.tv', '/siteinfo/panda.tv', '5.36'], ['26', 'Zhanqi.tv', '/siteinfo/zhanqi.tv', '5.34'], ['27', 'Alipay.com', '/siteinfo/alipay.com', '3.35'], ['28', 'Csdn.net', '/siteinfo/csdn.net', '4.86'], ['29', 'Bing.com', '/siteinfo/bing.com', '2.69'], ['30', 'Myshopify.com', '/siteinfo/myshopify.com', '13.07'], ['31', 'Vk.com', '/siteinfo/vk.com', '3.66'], ['32', 'Microsoftonline.com', '/siteinfo/microsoftonline.com', '1.91'], ['33', 'Yahoo.co.jp', '/siteinfo/yahoo.co.jp', '9.02'], ['34', 'Twitter.com', '/siteinfo/twitter.com', '10.40'], ['35', 'Canva.com', '/siteinfo/canva.com', '4.58'], ['36', 'Naver.com', '/siteinfo/naver.com', '13.10'], ['37', 'Bongacams.com', '/siteinfo/bongacams.com', '1.78'], ['38', 'Twitch.tv', '/siteinfo/twitch.tv', '4.20'], ['39', 'Aliexpress.com', '/siteinfo/aliexpress.com', '8.14'], ['40', 'Linkedin.com', '/siteinfo/linkedin.com', '9.23'], ['41', 'Ebay.com', '/siteinfo/ebay.com', '7.79'], ['42', 'Tianya.cn', '/siteinfo/tianya.cn', '5.12'], ['43', 'Force.com', '/siteinfo/force.com', '24.30'], ['44', 'Adobe.com', '/siteinfo/adobe.com', '3.61'], ['45', 'Amazon.in', '/siteinfo/amazon.in', '10.46'], ['46', 'Chaturbate.com', '/siteinfo/chaturbate.com', '8.51'], ['47', 'Huanqiu.com', '/siteinfo/huanqiu.com', '5.15'], ['48', 'Yy.com', '/siteinfo/yy.com', '5.25'], ['49', 'Amazon.co.jp', '/siteinfo/amazon.co.jp', '9.84'], ['50', 'Whatsapp.com', '/siteinfo/whatsapp.com', '1.19']]\n"
     ]
    }
   ],
   "source": [
    "print(alexa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56745ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>site_name</th>\n",
       "      <th>site_url</th>\n",
       "      <th>page_view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Google.com.hk</td>\n",
       "      <td>/siteinfo/google.com.hk</td>\n",
       "      <td>5.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sohu.com</td>\n",
       "      <td>/siteinfo/sohu.com</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank      site_name                 site_url page_view\n",
       "23   24  Google.com.hk  /siteinfo/google.com.hk      5.87\n",
       "6     7       Sohu.com       /siteinfo/sohu.com      4.57"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) 리스트 => 데이타프레임 \n",
    "# 5) 데이타프레임 => csv 저장 \n",
    "\n",
    "df_alexa = pd.DataFrame(alexa_list, columns=['rank', 'site_name', 'site_url', 'page_view'])\n",
    "df_alexa.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50920957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alexa.to_csv('output/alexa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8b920ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: 2819-FF50\n",
      "\n",
      " C:\\workspace211123\\output 디렉터리\n",
      "\n",
      "2021-11-29  오전 11:44    <DIR>          .\n",
      "2021-11-29  오전 11:44    <DIR>          ..\n",
      "2021-11-29  오전 11:44             2,096 alexa.csv\n",
      "2021-11-26  오후 01:55            40,508 df_gap1.csv\n",
      "2021-11-24  오후 02:37             1,972 rating100.csv\n",
      "2021-11-26  오후 05:07               240 평균분양가격_서울인천경기.csv\n",
      "               4개 파일              44,816 바이트\n",
      "               2개 디렉터리  71,000,338,432 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "ls output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7317bffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
