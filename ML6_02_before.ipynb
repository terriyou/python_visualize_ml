{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주피터 노트북 환경설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"retina\")\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { font-weight: bold !important; font-family:'Malgun Gothic' !important;}</style>\"))\n",
    "display(HTML(\"<style>.container { font-weight: bold !important;}</style>\"))\n",
    "display(HTML(\"<style>.container { width: 98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 관련 라이브러리 임포트 \n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "#  한글글꼴로 변경\n",
    "# plt.rcParams['font.family'] = '한글글꼴명'\n",
    "plt.rcParams['font.size'] = 11.0\n",
    "# plt.rcParams['font.family'] = 'batang'\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "# 그래프에서 마이너스 폰트 깨지는 문제에 대한 대처\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그래프 기본 크기 설정 \n",
    "plt.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, VotingRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, r2_score, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배깅(Bagging)\n",
    "- Bootstrap Aggregation. 앙상블 학습 방식 중 하나 \n",
    "- 배깅은 샘플을 여러 번 뽑아(Bootstrap) 각 모델을 학습시켜 결과물을 집계(Aggregration)하는 방법\n",
    "- 데이터로부터 부트스트랩(복원 랜덤 샘플링)을 하고 부트스트랩한 데이터로 모델을 학습. 학습된 모델의 결과를 집계하여 최종 결과 값을 구한다.\n",
    "- Categorical Data는 투표 방식(Votinig)으로 결과를 집계하며, Continuous Data는 평균으로 집계.\n",
    "- Categorical Data일 때, 투표 방식으로 한다는 것은 전체 모델에서 예측한 값 중 가장 많은 값을 최종 예측값으로 선정. \n",
    "- 6개의 결정 트리 모델일 경우 4개는 A로 예측했고, 2개는 B로 예측했다면 투표에 의해 4개의 모델이 선택한 A를 최종 결과로 예측한다\n",
    "- 평균으로 집계한다는 것은 말 그대로 각각의 결정 트리 모델이 예측한 값에 평균을 취해 최종 Bagging Model의 예측값을 결정한다\n",
    "- 배깅 기법을 활용한 모델이 바로 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb4wG8O%2FbtqyfYW98AS%2FYZBtUJy3jZLyuik1R0aGNk%2Fimg.png' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤 포레스트(Random Forest)\n",
    "\n",
    "- 여러 개의 분류기를 만들어서 보팅으로 최종 결정하는 알고리즘. \n",
    "- 여러 개의 결정 트리 분류기가 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링해 개별적으로 학습을 수행한 뒤 최종적으로 모든 분류기가 보팅을 통해 예측 결정을 내린다.\n",
    "- 개별적인 분류기의 기반 알고리즘은 결정 트리이지만 개별 트리가 학습하는 데이터 세트는 전체 데이터에서 일부가 중첩되게 샘플링된 데이터 세트인데 여러 개의 데이터 세트를 중첩되게 분리하는 것을 부트 스트래핑(bootstrapping) 분할 방식이라고 한다. \n",
    "\n",
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fod2gM%2Fbtq6kMv83oZ%2FsNVWEiA7FWsB2BBt6kn0r1%2Fimg.png'\n",
    "      width='500'>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Random Forest 주요 파라미터 \n",
    "\n",
    "n_estimators: 랜덤 포레스트 안의 결정 트리 갯수. 클수록 좋지만 메모리가 많이 소요됨\n",
    "max_features: 무작위로 선택할 Feature의 개수\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 데이타셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('data/titanic_book.csv')\n",
    "\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(),inplace=True)\n",
    "titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "titanic_df['Embarked'].fillna('N', inplace=True)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(titanic_df['Sex'])\n",
    "temp = encoder.transform(titanic_df['Sex'])\n",
    "titanic_df['Sex'] = temp.reshape(-1, 1)\n",
    "\n",
    "encoder.fit(titanic_df['Embarked'])\n",
    "temp = encoder.transform(titanic_df['Embarked'])\n",
    "titanic_df['Embarked'] = temp.reshape(-1, 1)\n",
    "\n",
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "encoder.fit(titanic_df['Cabin'])\n",
    "temp = encoder.transform(titanic_df['Cabin'])\n",
    "titanic_df['Cabin'] = temp.reshape(-1, 1)\n",
    "\n",
    "\n",
    "titanic_df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic_df = titanic_df.loc[:, 'Pclass':]\n",
    "y_titanic_df = titanic_df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이타와 테스트 데이타로 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \n",
    "                                                    test_size=0.2, random_state=11,\n",
    "                                                    stratify=y_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecesionTree 모델 적용과 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier()\n",
    "model_dt.fit(X_train, y_train)\n",
    "model_dt.score(X_train, y_train), model_dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier()\n",
    "parameters = {'max_depth':[3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "model_dt_grid = GridSearchCV(model_dt, param_grid=parameters, cv=5,  verbose=1)\n",
    "model_dt_grid.fit(X_train, y_train)\n",
    "model_dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier(max_depth = 3)\n",
    "model_dt.fit(X_train, y_train)\n",
    "model_dt.score(X_train, y_train), model_dt.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_importances = pd.Series(model_dt.feature_importances_ , index=X_train.columns  )\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x=ftr_importances , y = ftr_importances.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "model_rf.score(X_train, y_train), model_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = DecisionTreeClassifier()\n",
    "parameters = {'max_depth':[3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "model_rf_grid = GridSearchCV(model_rf, param_grid=parameters, cv=5,  verbose=1)\n",
    "model_rf_grid.fit(X_train, y_train)\n",
    "model_rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(max_depth = 3)\n",
    "model_rf.fit(X_train, y_train)\n",
    "model_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.classes_ , model_rf.feature_importances_, X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_values = model_rf.feature_importances_\n",
    "print(np.argsort(importances_values)[::-1])\n",
    "X_train.columns[np.argsort(importances_values)[::-1][:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_importances = pd.Series(model_rf.feature_importances_ , index=X_train.columns  )\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x=ftr_importances , y = ftr_importances.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 부스팅(Boosting)\n",
    "- 부스팅은 가중치를 활용하여 약 분류기를 강 분류기로 만드는 방법. \n",
    "- 배깅은 Deicison Tree1과 Decision Tree2가 서로 독립적으로 결과를 예측하며 여러 개의 독립적인 결정 트리가 각각 값을 예측한 뒤, 그 결과 값을 집계해 최종 결과 값을 예측하는 방식.\n",
    "- 부스팅은 모델 간 팀워크가 이루어져 처음 모델이 예측을 하면 그 예측 결과에 따라 데이터에 가중치가 부여되고, 부여된 가중치가 다음 모델에 영향을 준다. 잘못 분류된 데이터에 집중하여 새로운 분류 규칙을 만드는 단계를 반복한다. \n",
    "- ADA Boosting, Gradient Boosting\n",
    "\n",
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkCejr%2FbtqyghvqEZB%2F9o3rKTEsuSIDHEfelYFJlk%2Fimg.png' width='600'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM\n",
    "\n",
    "- Gradient Boosting Machine\n",
    "\n",
    "- max_depth\t: 트리의 최대 깊이. default = 3\n",
    "- min_samples_split\t: 노드를 분할하기 위한 최소한의 샘플 데이터수. → 과적합을 제어하는데 사용\n",
    "    <br> Default = 2 → 작게 설정할 수록 분할 노드가 많아져 과적합 가능성 증가\n",
    "- min_samples_leaf : 리프노드가 되기 위해 필요한 최소한의 샘플 데이터수.  \n",
    "    <br> min_samples_split과 함께 과적합 제어 용도.  default = 1\n",
    "- max_features : 최적의 분할을 위해 고려할 최대 feature 개수.  Default = 'none' → 모든 피처 사용\n",
    "- max_leaf_nodes : 리프노드의 최대 개수.  default = None → 제한없음\n",
    "- n_estimators\t: 생성할 트리의 갯수. Default = 100\n",
    "- learning_rate\t: 학습을 진행할 때마다 적용하는 학습률(0~1). \n",
    "    <br> Weak learner가 순차적으로 오류 값을 보정해나갈 때 적용하는 계수.  Default = 0.1\n",
    "    <br> 낮은 만큼 최소 오류 값을 찾아 예측성능이 높아질 수 있음. 시간이 많이 소요\n",
    "- subsample\t: 개별 트리가 학습에 사용하는 데이터 샘플링 비율(0~1). default=1 (전체 데이터 학습)\n",
    "    <br> 이 값을 조절하여 트리 간의 상관도를 줄일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train, y_train)\n",
    "model_gb.score(X_train, y_train), model_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators' : [50, 100, 300],\n",
    "    'learning_rate' : [0.01, 0.05, 0.1],\n",
    "    'max_depth':[3, 4, 5, 6]\n",
    "}\n",
    "model_gb_grid = GridSearchCV(model_gb, param_grid=parameters, cv=5,  verbose=1)\n",
    "model_gb_grid.fit(X_train, y_train)\n",
    "model_gb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, max_depth=5)\n",
    "model_gb.fit(X_train, y_train)\n",
    "model_gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, model_gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_importances = pd.Series(model_gb.feature_importances_ , index=X_train.columns  )\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x=ftr_importances , y = ftr_importances.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "- 트리 기반의 알고리즘의 앙상블 학습에서 각광받는 알고리즘 중 하나\n",
    "- GBM에 기반하고 있지만, GBM의 단점인 느린 수행시간, 과적합 규제 등을 해결한 알고리즘\n",
    "- 과적합 규제(Overfitting Regularization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설치 \n",
    "\n",
    "- sklearn 에서 지원되지 않으므로 별도 설치가 필요 \n",
    "- 관리자 버전으로 설치 \n",
    "- pip install xgboost\n",
    "- conda install -c anaconda py-xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 파라미터 \n",
    ": 트리 최적화, 부스팅, regularization 등과 관련된 파라미터를 지칭"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eta -  GBM의 learning rate와 같은 파라미터 범위: 0 ~ 1\n",
    "num_boost_around - 생성할 weak learner의 수\n",
    "min_child_weight - GBM의 min_samples_leaf와 유사. 관측치에 대한 가중치 합의 최소. 과적합 조절 용도 범위: 0 ~ ∞\n",
    "gamma - 리프노드의 추가분할을 결정할 최소손실 감소값. 값이 클수록 과적합 감소효과. 범위: 0 ~ ∞\n",
    "max_depth - 트리 기반 알고리즘의 max_depth와 동일. 0을 지정하면 깊이의 제한이 없음. 너무 크면 과적합(통상 3~10정도 적용)\n",
    "sub_sample - 데이터 샘플링 비율 지정(과적합 제어). 일반적으로 0.5~1 사이의 값을 사용. 범위: 0 ~ 1\n",
    "colsample_bytree - GBM의 max_features와 유사. 트리 생성에 필요한 피처의 샘플링에 사용. \n",
    "                   피처가 많을 때 과적합 조절에 사용. 범위: 0 ~ 1\n",
    "lambda - L2 Regularization 적용 값. 피처 개수가 많을 때 적용을 검토. 클수록 과적합 감소 효과\n",
    "alpha -  L1 Regularization 적용 값. 피처 개수가 많을 때 적용을 검토. 클수록 과적합 감소 효과\n",
    "scale_pos_weight - 불균형 데이터셋의 균형을 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import plot_importance, XGBClassifier \n",
    "\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 - 위스콘신 Breast Cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X_features= dataset.data\n",
    "y_label = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data=X_features, columns=dataset.feature_names)\n",
    "cancer_df['target']= y_label\n",
    "\n",
    "print(cancer_df.shape)\n",
    "cancer_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cancer_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancer_df.isnull().sum()\n",
    "cancer_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이타셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label,\n",
    "                                         test_size=0.2, random_state=156 )\n",
    "print(X_train.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgb = XGBClassifier()\n",
    "# 오류 발생시 아래와 같이 변경 \n",
    "model_xgb = XGBClassifier(objective='reg:squarederror', n_estimators=100)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "model_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model_xgb.predict(X_test)))\n",
    "confusion_matrix(y_test, model_xgb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(n_estimators=10)\n",
    "params = {\n",
    "    'max_depth':[5, 7, 9],\n",
    "    'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "model_xgb_gridcv = GridSearchCV(model_xgb, param_grid=params)\n",
    "model_xgb_gridcv.fit(X_train,\n",
    "           y_train,\n",
    "           eval_set=[(X_test, y_test)],\n",
    "           eval_metric=\"error\")\n",
    "print('GridSearchCV 최적 파라미터:', model_xgb_gridcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(objective='reg:squarederror', n_estimators=10, learning_rate=0.3, max_depth=5)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "model_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_importance_values = model_xgb.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importance_values, index=dataset.feature_names)\n",
    "ftr_importances = ftr_importances.sort_values(ascending=False)\n",
    "ftr_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=ftr_importances, y=ftr_importances.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPOJwXVwGQSikHrOscFum3b",
   "collapsed_sections": [],
   "name": "5-3 트리의 앙상블.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
